{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%attachments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spTraining\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "import os\n",
    "\n",
    "# Prepare training documents from a list of (id, text, label) tuples.\n",
    "def getProjectRepo():\n",
    "    repo = os.popen('bdvcli --get cluster.project_repo').read().rstrip()\n",
    "    if not repo:\n",
    "        print(\"unable to find, project repo, some history will be lost\")\n",
    "        return 'file:///tmp/'\n",
    "    return 'file://' + repo\n",
    "\n",
    "training = spark.createDataFrame([\n",
    "    (0, \"a b c d e spark\", 1.0),\n",
    "    (1, \"b d\", 0.0),\n",
    "    (2, \"spark f g h\", 1.0),\n",
    "    (3, \"hadoop mapreduce\", 0.0)\n",
    "], [\"id\", \"text\", \"label\"])\n",
    "\n",
    "# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.001)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n",
    "\n",
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(training)\n",
    "#print(type(model))\n",
    "model.save(getProjectRepo() + '/' + 'models/spark_models/TextPredction.model1')\n",
    "\n",
    "# Prepare test documents, which are unlabeled (id, text) tuples.\n",
    "# test = spark.createDataFrame([\n",
    "#     (4, \"spark i j k\"),\n",
    "#     (5, \"l m n\"),\n",
    "#     (6, \"spark hadoop spark\"),\n",
    "#     (7, \"apache hadoop\")\n",
    "# ], [\"id\", \"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching results from training cluster:sciKitTraining\n",
      "Received results from training cluster:sciKitTraining\n",
      "{\"id\":4,\"input\":\"['', 'from keras.models import Sequential', 'from keras.layers import Dense', 'from keras.models import model_from_json', 'import numpy', 'import os', '', 'def getProjectRepo(path):', \\\"    ProjectRepo = os.popen('bdvcli --get cluster.project_repo').read().rstrip()\\\", \\\"    return ProjectRepo + '/' + path        \\\", '# fix random seed for reproducibility', '', 'numpy.random.seed(7)', '# load pima indians dataset', 'dataset = numpy.loadtxt(getProjectRepo(\\\\'data/pima-indians-diabetes.csv\\\\'), delimiter=\\\",\\\")', '# split into input (X) and output (Y) variables', 'X = dataset[:,0:8]', 'Y = dataset[:,8]', '# create model', 'model = Sequential()', \\\"model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\\\", \\\"model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\\\", \\\"model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\", '# Compile model', \\\"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\\\", '# Fit the model', 'model.fit(X, Y, epochs=150, batch_size=10, verbose=0)', 'scores = model.evaluate(X, Y, verbose=0)', 'print(\\\"%s: %.2f%%\\\" % (model.metrics_names[1], scores[1]*100))', 'model_json = model.to_json()', 'with open(getProjectRepo(\\\\'models/demo1/model.json\\\\'), \\\"w\\\") as json_file:', '    json_file.write(model_json)', '# serialize weights to HDF5', \\\"model.save_weights(getProjectRepo('models/demo1/model.h5'))\\\", 'print(\\\"Saved model to disk\\\")']\",\"log\":\"/var/log/bluedata/request4\",\"output\":\"   2019-04-03 16:05:19.739767: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 Using TensorFlow backend. acc: 75.13% Saved model to disk  \",\"status\":\"Finished\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sciKitTraining\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "import numpy\n",
    "import os\n",
    "\n",
    "def getProjectRepo(path):\n",
    "    ProjectRepo = os.popen('bdvcli --get cluster.project_repo').read().rstrip()\n",
    "    return ProjectRepo + '/' + path        \n",
    "# fix random seed for reproducibility\n",
    "\n",
    "numpy.random.seed(7)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(getProjectRepo('data/pima-indians-diabetes.csv'), delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "model_json = model.to_json()\n",
    "with open(getProjectRepo('models/demo1/model.json'), \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(getProjectRepo('models/demo1/model.h5'))\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
